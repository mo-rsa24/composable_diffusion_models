{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-28T23:07:41.808111Z",
     "start_time": "2025-07-28T23:07:39.432399Z"
    }
   },
   "source": [
    "# Cell 1\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:07:44.901554Z",
     "start_time": "2025-07-28T23:07:44.765513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2\n",
    "def color_mnist_digit(digit, color, root='./data', train=True):\n",
    "    mnist = datasets.MNIST(root=root, train=train, download=True)\n",
    "    idx = (mnist.targets == digit)\n",
    "    images = mnist.data[idx].float() / 255.0\n",
    "    images = images.unsqueeze(1)  # [N,1,28,28]\n",
    "    zeros = torch.zeros_like(images)\n",
    "    if color == 'red':\n",
    "        rgb = torch.cat([images, zeros, zeros], 1)\n",
    "    elif color == 'green':\n",
    "        rgb = torch.cat([zeros, images, zeros], 1)\n",
    "    else:\n",
    "        raise ValueError(\"color must be 'red' or 'green'\")\n",
    "    return rgb\n",
    "\n",
    "red_6_imgs = color_mnist_digit(6, 'red')\n",
    "green_2_imgs = color_mnist_digit(2, 'green')"
   ],
   "id": "c866c2be0ff75f6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:08:04.766764Z",
     "start_time": "2025-07-28T23:08:04.763574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3\n",
    "beta_0 = 0.1\n",
    "beta_1 = 20.0\n",
    "\n",
    "def log_alpha(t):\n",
    "    return -0.5 * t * beta_0 - 0.25 * t ** 2 * (beta_1 - beta_0)\n",
    "\n",
    "def log_sigma(t):\n",
    "    return torch.log(torch.clamp(t, min=1e-6))\n",
    "\n",
    "def dlog_alphadt(t):\n",
    "    t = t.detach().requires_grad_(True)\n",
    "    out = log_alpha(t)\n",
    "    grad_out = torch.autograd.grad(out.sum(), t, create_graph=True)[0]\n",
    "    return grad_out\n",
    "\n",
    "def beta(t):\n",
    "    return (1 + 0.5 * t * beta_0 + 0.5 * t ** 2 * (beta_1 - beta_0))"
   ],
   "id": "504efb959e6ca9e6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:08:09.119014Z",
     "start_time": "2025-07-28T23:08:09.115202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 4\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, base_channels=32):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels+1, base_channels, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, base_channels*2, 3, padding=1), nn.ReLU(),\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels*2, 3, padding=1), nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "    def forward(self, x, t):\n",
    "        t_img = t.view(-1,1,1,1).expand(-1,1,28,28)\n",
    "        x = torch.cat([x, t_img], 1)\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "id": "58af5da7fd639215",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:08:13.283177Z",
     "start_time": "2025-07-28T23:08:13.278847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 5\n",
    "def train_score_model(model, images, epochs=5, batch_size=64, device='cpu'):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "    dataset = TensorDataset(images)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        for (x,) in loader:\n",
    "            x = x.to(device)\n",
    "            bs = x.size(0)\n",
    "            t = torch.rand(bs, 1, device=device)\n",
    "            eps = torch.randn_like(x)\n",
    "            x_t = torch.exp(log_alpha(t))[:, None, None, None] * x \\\n",
    "                + torch.exp(log_sigma(t))[:, None, None, None] * eps\n",
    "            score = model(x_t, t)\n",
    "            loss = ((score + eps)**2).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model"
   ],
   "id": "9ebcff8c72a1eb86",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:08:18.776349Z",
     "start_time": "2025-07-28T23:08:18.189235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 6\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_red = SimpleUNet().to(device)\n",
    "model_green = SimpleUNet().to(device)\n",
    "\n",
    "model_red = train_score_model(model_red, red_6_imgs.to(device), epochs=5, device=device)\n",
    "model_green = train_score_model(model_green, green_2_imgs.to(device), epochs=5, device=device)"
   ],
   "id": "98b926424586f873",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_352110/1798967990.py\", line 6, in <module>\n",
      "    model_red = train_score_model(model_red, red_6_imgs.to(device), epochs=5, device=device)\n",
      "  File \"/tmp/ipykernel_352110/2268791827.py\", line 15, in train_score_model\n",
      "    score = model(x_t, t)\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_352110/1671143704.py\", line 18, in forward\n",
      "    x = torch.cat([x, t_img], 1)\n",
      "RuntimeError: Tensors must have same number of dimensions: got 5 and 4\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1110, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 992, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 804, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/stack_data/core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/stack_data/core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"/home/molef/micromamba/envs/cxr_superdiff/lib/python3.10/site-packages/stack_data/core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8db31f578b906a2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
